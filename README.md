# E-commerce Chatbot

A comprehensive end-to-end machine learning project for building and deploying an intelligent e-commerce chatbot. This project combines modern MLOps practices with a production-ready web application, featuring automated hyperparameter optimization, model fine-tuning, intelligent model selection, and automated deployment to Hugging Face Hub.

## ğŸš€ Features

- **ğŸ¤– Advanced Chatbot**: Fine-tuned TinyLlama model for e-commerce conversations
- **ğŸ”„ MLOps Pipeline**: Automated data preprocessing, training, evaluation, and deployment with DVC
- **ğŸ¯ Hyperparameter Optimization**: Automated HPO using Optuna with MLflow tracking
- **ğŸ“Š Experiment Tracking**: Comprehensive logging with MLflow and DagHub integration
- **ğŸ§  Intelligent Model Selection**: Weighted scoring system using BLEU 1-4 and ROUGE-L metrics
- **ğŸš€ Automated Deployment**: Smart deployment to MLflow Model Registry and Hugging Face Hub
- **ğŸŒ Web Application**: Modern Next.js chatbot interface with real-time conversations
- **âš¡ CI/CD Pipeline**: Automated GitHub Actions workflow for feature development
- **ğŸ“ˆ Model Evaluation**: Comprehensive BLEU and ROUGE metrics for response quality assessment

## ğŸ—ï¸ Architecture

### ML Pipeline

```
Data Preprocessing â†’ HPO â†’ Fine-tuning â†’ Evaluation â†’ Model Selection â†’ Deployment
```

### Deployment Pipeline

```
Performance Comparison â†’ Quality Gate â†’ MLflow Registry â†’ Hugging Face Hub
```

### Tech Stack

- **ML Framework**: PyTorch, Transformers, PEFT (LoRA)
- **Model**: TinyLlama/TinyLlama-1.1B-Chat-v1.0
- **MLOps**: DVC, MLflow, DagHub
- **HPO**: Optuna
- **Model Selection**: Weighted BLEU/ROUGE scoring
- **Deployment**: MLflow Model Registry, Hugging Face Hub
- **Frontend**: Next.js 15, React, TypeScript, Tailwind CSS
- **Data Storage**: AWS S3
- **Application Database**: PostgreSQL with NEON Serverless Postgres
- **Deployment**: Vercel (Frontend), GitHub Actions (CI/CD)

## ğŸ“ Project Structure

```
E-commerce-Chatbot/
â”œâ”€â”€ app/ai-chatbot/                 # Next.js web application
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”œâ”€â”€ app/                       # Next.js app router
â”‚   â”œâ”€â”€ lib/                       # Utilities and database
â”‚   â”œâ”€â”€ hooks/                     # Custom React hooks
â”‚   â””â”€â”€ package.json               # Frontend dependencies
â”œâ”€â”€ src/                           # ML source code
â”‚   â”œâ”€â”€ data_prep.py              # Data preprocessing with ChatML format
â”‚   â”œâ”€â”€ fine_tuning.py            # Model fine-tuning with LoRA
â”‚   â”œâ”€â”€ evaluation.py             # Model evaluation metrics and pipeline
â”‚   â”œâ”€â”€ model_selection.py        # Weighted scoring and model comparison
â”‚   â”œâ”€â”€ deployment.py             # Hugging Face deployment functions
â”‚   â”œâ”€â”€ hpo.py                    # Hyperparameter optimization
â”‚   â””â”€â”€ rag_setup.py              # RAG implementation (future)
â”œâ”€â”€ scripts/                       # Executable scripts (argument parsing only)
â”‚   â”œâ”€â”€ data_prep_script.py       # Data preprocessing entry point
â”‚   â”œâ”€â”€ fine_tuning_script.py     # Fine-tuning entry point
â”‚   â”œâ”€â”€ evaluation_script.py      # Evaluation entry point
â”‚   â”œâ”€â”€ deployment_script.py      # Deployment pipeline entry point
â”‚   â”œâ”€â”€ push_to_huggingface_script.py # Standalone HF deployment
â”‚   â””â”€â”€ hpo_script.py             # HPO entry point
â”œâ”€â”€ utils/                         # Utility modules
â”‚   â”œâ”€â”€ mlflow_utils.py           # MLflow integration
â”‚   â”œâ”€â”€ huggingface_utils.py      # Hugging Face utilities
â”‚   â”œâ”€â”€ system_utils.py           # GPU/device utilities
â”‚   â”œâ”€â”€ yaml_utils.py             # Configuration utilities
â”‚   â””â”€â”€ constants.py              # Project constants
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Original e-commerce datasets
â”‚   â”œâ”€â”€ processed/                # ChatML formatted JSONL files
â”‚   â””â”€â”€ evaluation/               # Test datasets
â”œâ”€â”€ results/                       # Training outputs and evaluations
â”‚   â”œâ”€â”€ evaluations/              # Model evaluation results
â”‚   â””â”€â”€ deployment/               # Deployment decisions and logs
â”œâ”€â”€ configs/                       # Configuration files
â”œâ”€â”€ docs/                         # Documentation
â”‚   â””â”€â”€ DEPLOYMENT.md             # Deployment pipeline documentation
â”œâ”€â”€ .github/workflows/             # CI/CD pipeline
â”œâ”€â”€ dvc.yaml                      # DVC pipeline definition
â”œâ”€â”€ params.yaml                   # Model and training parameters
â””â”€â”€ requirements.txt              # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- Node.js 18+ (for web app)
- CUDA-compatible GPU (recommended)
- Git and DVC

### 1. Clone and Setup

```bash
git clone https://github.com/ShenghaoisYummy/E-commerce-Chatbot.git
cd E-commerce-Chatbot

# Install Python dependencies
pip install -r requirements.txt

# Setup DVC (if using remote storage)
dvc remote add -d storage s3://your-bucket/path
```

### 2. Configure Environment

```bash
# Create .env file with your credentials
# Create .env file with your credentials
export DAGSHUB_USER_TOKEN="your_token"
export MLFLOW_TRACKING_USERNAME="your_username"
export MLFLOW_TRACKING_PASSWORD="your_password"
export HF_TOKEN="your_huggingface_token"  # For deployment

export AWS_ACCESS_KEY_ID="your_aws_access_key"
export AWS_SECRET_ACCESS_KEY="your_aws_secret_key"
export MLFLOW_TRACKING_URI="https://dagshub.com/ShenghaoisYummy/E-commerce-Chatbot.mlflow"

```

### 3. Run ML Pipeline

#### Option A: Full Automated Pipeline with Deployment

```bash
# Run complete pipeline with HPO and smart deployment
dvc repro
```

#### Option B: Step-by-Step Execution

```bash
# 1. Data preprocessing
python scripts/data_prep_script.py

# 2. Hyperparameter optimization (optional)
python scripts/hpo_script.py --n-trials 10

# 3. Model fine-tuning
python scripts/fine_tuning_script.py

# 4. Model evaluation
python scripts/evaluation_script.py

# 5. Smart deployment (only deploys if model improves)
python scripts/deployment_script.py
```

#### Option C: Manual Deployment

```bash
# Deploy to Hugging Face Hub directly
python scripts/push_to_huggingface_script.py --hf-model-id YourUsername/YourModel

# Test Hugging Face connection
python scripts/push_to_huggingface_script.py --test-connection
```

### 4. Launch Web Application

```bash
cd app/ai-chatbot
pnpm install
pnpm dev
```

Visit `http://localhost:3000` to interact with your chatbot!

## ğŸ”§ Configuration

### Model Configuration (`params.yaml`)

```yaml
model:
  base_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  device:
    use_gpu: true
    precision: "float32"

lora:
  r: 16
  alpha: 32
  dropout: 0.05

training:
  epochs: 2
  batch_size: 4
  learning_rate: 0.0005
  max_length: 512

# New: Deployment configuration
deployment:
  min_improvement_threshold: 0.001
  model_registry_name: "ecommerce-chatbot"
  huggingface:
    model_id: "YourUsername/YourModel"
    push_to_hub: true
  weighted_scoring:
    weights:
      bleu1: 0.10 # Basic vocabulary coverage
      bleu2: 0.15 # Phrase fluency
      bleu3: 0.25 # Local grammar structure
      bleu4: 0.40 # Overall quality (most important)
      rougeL_precision: 0.10 # Content relevance
```

### Data Format

The project uses ChatML format for training:

```json
{
  "text": "<|im_start|>system\nYou are a helpful e-commerce assistant.<|im_end|>\n<|im_start|>user\nWhat's the return policy?<|im_end|>\n<|im_start|>assistant\nOur return policy allows returns within 30 days...<|im_end|>"
}
```

## ğŸ§  Intelligent Model Selection

### Weighted Scoring System

The deployment pipeline uses a sophisticated weighted scoring system:

- **BLEU-4 (40%)**: Overall response quality and completeness
- **BLEU-3 (25%)**: Local grammar structure and coherence
- **BLEU-2 (15%)**: Phrase fluency and natural combinations
- **BLEU-1 (10%)**: Basic vocabulary coverage
- **ROUGE-L Precision (10%)**: Content relevance and precision

### Deployment Criteria

A model is automatically deployed if:

1. **It's the first model** (no historical data), OR
2. **It achieves the highest weighted score** in history, AND
3. **Improvement exceeds minimum threshold** (configurable, default: 0.001)

### Performance Tracking

```bash
# View model comparison results
cat results/deployment/model_comparison.json

# Check deployment decision
cat results/deployment/deployment_info.json
```

## ğŸ“Š Experiment Tracking

### MLflow Integration

- **Tracking URI**: https://dagshub.com/ShenghaoisYummy/E-commerce-Chatbot.mlflow
- **Experiments**: Automatic logging of parameters, metrics, and artifacts
- **Model Registry**: Versioned model storage with automatic promotion to "Production"
- **Deployment Tracking**: Complete audit trail of deployment decisions

### Metrics Tracked

- **Training**: Loss, learning rate, gradient norms
- **Evaluation**: BLEU 1-4, ROUGE-L precision/recall/F1, weighted scores
- **HPO**: Combined scores, parameter combinations
- **Deployment**: Performance comparisons, deployment decisions, model versions

## ğŸš€ Deployment Pipeline

### Automated Deployment

The deployment pipeline automatically:

1. **Evaluates** the model using comprehensive metrics
2. **Compares** performance with historical best using weighted scoring
3. **Decides** whether to deploy based on improvement thresholds
4. **Registers** best models in MLflow Model Registry
5. **Deploys** to Hugging Face Hub with comprehensive model cards
6. **Tracks** all decisions and performance in MLflow

### Manual Deployment Options

```bash
# Force deployment regardless of performance
python scripts/deployment_script.py --force-deploy

# Skip Hugging Face deployment
python scripts/deployment_script.py --skip-hf-push

# Deploy with custom threshold
python scripts/deployment_script.py --min-improvement-threshold 0.01

# Standalone Hugging Face deployment
python scripts/push_to_huggingface_script.py \
  --hf-model-id YourUsername/YourModel \
  --commit-message "Deploy latest model"
```

## ğŸ”„ CI/CD Pipeline

The project includes automated GitHub Actions workflows:

### Feature Development Pipeline

- **Trigger**: Push to feature branches
- **Steps**:
  1. Data preprocessing
  2. Hyperparameter optimization
  3. Model fine-tuning
  4. Evaluation with weighted scoring
  5. Smart deployment decision
  6. MLflow Model Registry update
  7. Hugging Face Hub deployment (if approved)
  8. Results commit and push

### Pipeline Features

- **Automatic parameter updates** from HPO
- **DVC integration** for data versioning
- **MLflow logging** for experiment tracking
- **Smart deployment** with quality gates
- **Artifact management** with cloud storage
- **Force deployment** option for manual override

## ğŸ¯ Hyperparameter Optimization

### Optuna Integration

```bash
python scripts/hpo_script.py \
  --n-trials 20 \
  --n-jobs 4 \
  --config params.yaml
```

### Search Space

- **LoRA parameters**: r (8-32), alpha (16-64), dropout (0.05-0.2)
- **Training parameters**: learning_rate, weight_decay, batch_size, warmup_steps
- **Optimization**: Weighted BLEU + ROUGE score

### Automatic Parameter Updates

HPO automatically updates `params.yaml` with the best parameters found, which are then used in subsequent training runs.

## ğŸ“ˆ Model Performance

### Evaluation Metrics

- **BLEU 1-4**: Measures n-gram overlap with reference responses
- **ROUGE-L**: Evaluates longest common subsequence precision/recall/F1
- **Weighted Score**: Intelligent combination prioritizing response quality

### Performance Comparison

The system automatically compares:

- Current model vs. historical best
- Improvement percentage and absolute gains
- Contribution breakdown by metric
- Deployment recommendation

### Current Results

- **Model**: TinyLlama-1.1B-Chat-v1.0 with LoRA fine-tuning
- **Training**: ChatML formatted e-commerce conversations
- **Evaluation**: Automated metrics with comprehensive reporting
- **Deployment**: Smart deployment based on performance improvements

## ğŸŒ Web Application

### Features

- **Real-time chat interface** with streaming responses
- **Conversation history** with persistent storage
- **Modern UI** with dark/light mode support
- **Responsive design** for mobile and desktop
- **Authentication** with NextAuth.js
- **Model integration** with deployed Hugging Face models

### Tech Stack

- **Framework**: Next.js 15 with App Router
- **Styling**: Tailwind CSS with Radix UI components
- **Database**: PostgreSQL with Drizzle ORM
- **Deployment**: Vercel with edge functions

## ğŸš€ Deployment Options

### Model Deployment

1. **MLflow Model Registry**: Automatic registration and versioning
2. **Hugging Face Hub**: Public model sharing with comprehensive model cards
3. **Local**: Direct model loading from checkpoints
4. **API**: RESTful endpoints for inference

### Web App Deployment

```bash
cd app/ai-chatbot
pnpm build
pnpm start
```

### Environment Variables for Deployment

```bash
# MLflow/DagHub
DAGSHUB_USER_TOKEN=your_dagshub_token
MLFLOW_TRACKING_URI=https://dagshub.com/username/repo.mlflow

# Hugging Face
HF_TOKEN=your_huggingface_token

# Optional: AWS for DVC
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
```

## ğŸ“š Documentation

- **[Deployment Pipeline](docs/DEPLOYMENT.md)**: Comprehensive deployment documentation
- **Model Cards**: Automatically generated on Hugging Face Hub
- **MLflow Experiments**: Detailed experiment tracking and comparison
- **Code Documentation**: Inline documentation and type hints

## ğŸ¤ Contributing

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Development Workflow

- Use feature branches for development
- CI/CD pipeline runs automatically on push
- HPO updates parameters automatically
- Smart deployment only deploys improved models
- All experiments tracked in MLflow

### Code Structure

- **Scripts**: Only argument parsing and main execution
- **Modules**: All business logic and complex functions
- **Utils**: Shared utilities and helpers
- **Configs**: Centralized configuration management

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **TinyLlama** team for the base model
- **Hugging Face** for transformers, datasets, and Hub
- **MLflow** and **DVC** for MLOps infrastructure
- **Optuna** for hyperparameter optimization
- **Vercel** for deployment platform

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/ShenghaoisYummy/E-commerce-Chatbot/issues)
- **Discussions**: [GitHub Discussions](https://github.com/ShenghaoisYummy/E-commerce-Chatbot/discussions)
- **MLflow**: [Experiment Tracking](https://dagshub.com/ShenghaoisYummy/E-commerce-Chatbot.mlflow)
- **Documentation**: [Deployment Guide](docs/DEPLOYMENT.md)

## ğŸ”— Quick Links

- **ğŸ¤— Hugging Face Model**: [TinyLlama-ECommerce-Chatbot](https://huggingface.co/ShenghaoYummy/TinyLlama-ECommerce-Chatbot)
- **ğŸ“Š MLflow Experiments**: [DagHub MLflow](https://dagshub.com/ShenghaoisYummy/E-commerce-Chatbot.mlflow)
- **ğŸŒ Live Demo**: [Chatbot Web App](https://your-app-url.vercel.app)
- **ğŸ“– Deployment Docs**: [DEPLOYMENT.md](docs/DEPLOYMENT.md)

---

**Built with â¤ï¸ for the e-commerce community**
